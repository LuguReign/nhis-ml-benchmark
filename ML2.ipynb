{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-17T18:30:09.773368Z",
     "start_time": "2025-10-17T18:28:50.920112Z"
    }
   },
   "source": [
    "# file: src/run_srh_prediction_lean.py\n",
    "# Lean NHIS SRH prediction: Adults23 -> Adults24\n",
    "# Pipeline: preprocess -> (L1 or RF) -> calibrate -> OOF threshold -> external eval -> lite interpretation\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import datetime\n",
    "from inspect import signature\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from packaging import version\n",
    "import sklearn\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    average_precision_score,\n",
    "    balanced_accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder, StandardScaler\n",
    "\n",
    "RNG = 42\n",
    "np.random.seed(RNG)\n",
    "\n",
    "# =========================\n",
    "# CONFIG (edit paths as needed)\n",
    "# =========================\n",
    "DATA_TRAIN = \"/Users/lugu_reign/Desktop/RA PROJECT/adult24csv/Adults23_corefeatures.parquet\"\n",
    "DATA_TEST  = \"/Users/lugu_reign/Desktop/RA PROJECT/adult24csv/Adults24_corefeatures.parquet\"\n",
    "WEIGHT_COL = \"WTFA_A\"\n",
    "TARGET_RAW = \"PHSTAT_A\"  # 1..5\n",
    "\n",
    "# Models\n",
    "RF_CLASS_WEIGHT = \"balanced_subsample\"    # or None\n",
    "LOGIT_CLASS_WEIGHT = \"balanced\"           # or None\n",
    "CALIBRATION_METHOD = \"isotonic\"           # \"isotonic\" or \"sigmoid\"\n",
    "CALIBRATION_CV = 5\n",
    "N_SPLITS_OOF = 5\n",
    "\n",
    "# =========================\n",
    "# FEATURES\n",
    "# =========================\n",
    "FEATURES = [\n",
    "    \"RATCAT_A\",\"POVRATTC_A\",\n",
    "    \"EDUCP_A\",\"MAXEDUCP_A\",\n",
    "    \"EMPWKHRS3_A\",\"EMPWRKFT1_A\",\"EMPHEALINS_A\",\"EMPSICKLV_A\",\"EMPLASTWK_A\",\n",
    "    \"EMPNOWRK_A\",\"EMPWHENWRK_A\",\"EMDSUPER_A\",\n",
    "    \"MARITAL_A\",\"MARSTAT_A\",\"LONELY_A\",\"SUPPORT_A\",\"URBRRL23\",\"REGION\",\n",
    "    \"FDSCAT3_A\",\"FDSCAT4_A\",\n",
    "    \"DISAB3_A\",\"ANYDIFF_A\",\"DIFF_A\",\"COGMEMDFF_A\",\"COMDIFF_A\",\"VISIONDF_A\",\"HEARINGDF_A\",\n",
    "    \"K6SPD_A\",\"WORTHLESS_A\",\"HOPELESS_A\",\"SAD_A\",\"NERVOUS_A\",\"RESTLESS_A\",\"EFFORT_A\",\n",
    "    \"DEPFREQ_A\",\"ANXFREQ_A\",\"DEPLEVEL_A\",\"DEPMED_A\",\"ANXMED_A\",\"MHRX_A\",\"MHTHRPY_A\",\n",
    "    \"MHTHDLY_A\",\"MHTHND_A\",\n",
    "    \"HYPEV_A\",\"DIBEV_A\",\"CHDEV_A\",\"MIEV_A\",\"STREV_A\",\"ANGEV_A\",\n",
    "    \"ASEV_A\",\"ASTILL_A\",\"ARTHEV_A\",\"COPDEV_A\",\"CANEV_A\",\n",
    "    \"CHLEV_A\",\"CHL12M_A\",\"HYP12M_A\",\"HYPMED_A\",\"KIDWEAKEV_A\",\"LIVEREV_A\",\"HEPEV_A\",\n",
    "    \"CROHNSEV_A\",\"ULCCOLEV_A\",\"PSOREV_A\",\"CFSNOW_A\",\n",
    "    \"HICOV_A\",\"USUALPL_A\",\"MEDNG12M_A\",\"MEDDL12M_A\",\"RXDG12M_A\",\"LASTDR_A\",\"WELLVIS_A\"\n",
    "]\n",
    "\n",
    "BINARY_12 = [\n",
    "    \"EMPWRKFT1_A\",\"EMPHEALINS_A\",\"EMPSICKLV_A\",\"EMPLASTWK_A\",\"DISAB3_A\",\"ANYDIFF_A\",\n",
    "    \"DIFF_A\",\"COGMEMDFF_A\",\"COMDIFF_A\",\"VISIONDF_A\",\"HEARINGDF_A\",\n",
    "    \"K6SPD_A\",\"DEPMED_A\",\"ANXMED_A\",\"MHRX_A\",\"MHTHRPY_A\",\"MHTHDLY_A\",\"MHTHND_A\",\n",
    "    \"HYPEV_A\",\"DIBEV_A\",\"CHDEV_A\",\"MIEV_A\",\"STREV_A\",\"ANGEV_A\",\"ASEV_A\",\"ASTILL_A\",\n",
    "    \"ARTHEV_A\",\"COPDEV_A\",\"CANEV_A\",\"CHLEV_A\",\"CHL12M_A\",\"HYP12M_A\",\"HYPMED_A\",\n",
    "    \"KIDWEAKEV_A\",\"LIVEREV_A\",\"HEPEV_A\",\"CROHNSEV_A\",\"ULCCOLEV_A\",\"PSOREV_A\",\"CFSNOW_A\",\n",
    "    \"HICOV_A\",\"USUALPL_A\",\"MEDNG12M_A\",\"MEDDL12M_A\",\"RXDG12M_A\",\"EMDSUPER_A\"\n",
    "]\n",
    "\n",
    "ORDINAL_NUMERIC = [\n",
    "    \"RATCAT_A\",\"POVRATTC_A\",\"EDUCP_A\",\"MAXEDUCP_A\",\n",
    "    \"LONELY_A\",\"SUPPORT_A\",\"FDSCAT3_A\",\"FDSCAT4_A\",\n",
    "    \"WORTHLESS_A\",\"HOPELESS_A\",\"SAD_A\",\"NERVOUS_A\",\"RESTLESS_A\",\"EFFORT_A\",\n",
    "    \"DEPFREQ_A\",\"ANXFREQ_A\",\"DEPLEVEL_A\",\n",
    "    \"EMPWKHRS3_A\",\"LASTDR_A\",\"WELLVIS_A\"\n",
    "]\n",
    "\n",
    "CATEGORICAL = [\"MARITAL_A\",\"MARSTAT_A\",\"URBRRL23\",\"REGION\",\"EMPNOWRK_A\",\"EMPWHENWRK_A\"]\n",
    "\n",
    "# =========================\n",
    "# Pickle-safe top-level transformers (no lambdas)\n",
    "# =========================\n",
    "def select_reindex_func(X, cols):\n",
    "    import pandas as pd, numpy as np\n",
    "    X = pd.DataFrame(X)\n",
    "    return X.reindex(columns=cols, fill_value=np.nan)\n",
    "\n",
    "def map_12_binary_func(X, cols):\n",
    "    import pandas as pd, numpy as np\n",
    "    out = pd.DataFrame(X, copy=True)\n",
    "    for c in cols:\n",
    "        if c in out.columns:\n",
    "            out[c] = out[c].replace({1: 1.0, 2: 0.0})\n",
    "            out[c] = out[c].where(out[c].isin([0.0, 1.0]), np.nan)\n",
    "    return out\n",
    "\n",
    "def clean_ordinals_func(X, cols):\n",
    "    import pandas as pd, numpy as np\n",
    "    out = pd.DataFrame(X, copy=True)\n",
    "    for c in cols:\n",
    "        if c in out.columns:\n",
    "            out[c] = out[c].replace({7: np.nan, 8: np.nan, 9: np.nan})\n",
    "    return out\n",
    "\n",
    "# =========================\n",
    "# General helpers\n",
    "# =========================\n",
    "def normalize_weights(w: pd.Series) -> np.ndarray:\n",
    "    w = w.fillna(0).clip(lower=0)\n",
    "    return (w / (w.mean() if w.mean() > 0 else 1.0)).to_numpy()\n",
    "\n",
    "def make_binary_srh(df: pd.DataFrame, col=\"PHSTAT_A\") -> pd.Series:\n",
    "    x = df[col].replace({7: np.nan, 8: np.nan, 9: np.nan})\n",
    "    return (x >= 4).astype(\"float64\")  # 1 = Fair/Poor\n",
    "\n",
    "def subset_existing(df: pd.DataFrame, cols: List[str]) -> List[str]:\n",
    "    return [c for c in cols if c in df.columns]\n",
    "\n",
    "def make_ohe() -> OneHotEncoder:\n",
    "    # sklearn>=1.4 uses sparse_output; older uses sparse\n",
    "    if version.parse(sklearn.__version__) >= version.parse(\"1.4\"):\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True)\n",
    "    else:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse=True)\n",
    "\n",
    "def feature_names_from_preprocessor(prep: ColumnTransformer, n_features: int) -> List[str]:\n",
    "    \"\"\"Ensure we always return exactly n_features names; fall back to generic.\"\"\"\n",
    "    names: List[str] = []\n",
    "    try:\n",
    "        names = list(prep.get_feature_names_out())\n",
    "    except Exception:\n",
    "        names = []\n",
    "    if not names:\n",
    "        tmp = []\n",
    "        for name, trans, cols in getattr(prep, \"transformers_\", []):\n",
    "            if name == \"cat\":\n",
    "                try:\n",
    "                    ohe = trans.named_steps[\"ohe\"]\n",
    "                    tmp.extend(ohe.get_feature_names_out().tolist())\n",
    "                except Exception:\n",
    "                    pass\n",
    "            elif name in (\"bin\", \"ord\"):\n",
    "                # Prefer the 'select' step's kw_args (exact list used)\n",
    "                try:\n",
    "                    sel = trans.named_steps.get(\"select\", None)\n",
    "                    if sel is not None and hasattr(sel, \"kw_args\"):\n",
    "                        sel_cols = sel.kw_args.get(\"cols\", None)\n",
    "                        if sel_cols is not None:\n",
    "                            tmp.extend(list(sel_cols))\n",
    "                        else:\n",
    "                            tmp.extend(list(cols) if isinstance(cols, list) else [])\n",
    "                    else:\n",
    "                        tmp.extend(list(cols) if isinstance(cols, list) else [])\n",
    "                except Exception:\n",
    "                    tmp.extend(list(cols) if isinstance(cols, list) else [])\n",
    "        names = tmp\n",
    "    if len(names) != n_features:\n",
    "        names = [f\"f{i}\" for i in range(n_features)]\n",
    "    return names\n",
    "\n",
    "def class_prevalence(y: np.ndarray, w: np.ndarray) -> Dict[str, float]:\n",
    "    p_unw = y.mean()\n",
    "    p_w = (y * w).sum() / (w.sum() if w.sum() > 0 else 1.0)\n",
    "    return {\"positive_unweighted\": float(p_unw), \"positive_weighted\": float(p_w)}\n",
    "\n",
    "def fit_with_weights(pipeline: Pipeline, X, y, w):\n",
    "    last_name, _ = pipeline.steps[-1]\n",
    "    param = f\"{last_name}__sample_weight\"\n",
    "    try:\n",
    "        pipeline.fit(X, y, **{param: w})\n",
    "    except TypeError:\n",
    "        print(f\"Note: '{last_name}' does not accept sample_weight; fitting unweighted.\")\n",
    "        pipeline.fit(X, y)\n",
    "\n",
    "def fit_calibrated(cal: CalibratedClassifierCV, X, y, w):\n",
    "    try:\n",
    "        cal.fit(X, y, sample_weight=w)  # sklearn may ignore this; fine.\n",
    "    except TypeError:\n",
    "        print(\"Note: CalibratedClassifierCV.fit has no sample_weight; fitting unweighted.\")\n",
    "        cal.fit(X, y)\n",
    "\n",
    "def oof_predict_proba(estimator, X: pd.DataFrame, y: np.ndarray, w: np.ndarray,\n",
    "                      n_splits: int = 5) -> np.ndarray:\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RNG)\n",
    "    oof = np.zeros(len(y), dtype=float)\n",
    "    for tr, va in skf.split(X, y):\n",
    "        model = copy.deepcopy(estimator)\n",
    "        if isinstance(model, Pipeline):\n",
    "            try:\n",
    "                fit_with_weights(model, X.iloc[tr], y[tr], w[tr])\n",
    "            except Exception:\n",
    "                model.fit(X.iloc[tr], y[tr])\n",
    "        else:\n",
    "            try:\n",
    "                model.fit(X.iloc[tr], y[tr], sample_weight=w[tr])\n",
    "            except TypeError:\n",
    "                model.fit(X.iloc[tr], y[tr])\n",
    "        oof[va] = model.predict_proba(X.iloc[va])[:, 1]\n",
    "    return oof\n",
    "\n",
    "def find_best_threshold(y_true: np.ndarray, p_hat: np.ndarray, w: np.ndarray,\n",
    "                        metric: str = \"f1\") -> Tuple[float, float]:\n",
    "    ths = np.linspace(0.05, 0.95, 19)\n",
    "    best_score, best_t = -np.inf, 0.5\n",
    "    for t in ths:\n",
    "        yb = (p_hat >= t).astype(int)\n",
    "        if metric == \"f1\":\n",
    "            s = f1_score(y_true, yb, sample_weight=w)\n",
    "        elif metric == \"bal_acc\":\n",
    "            s = balanced_accuracy_score(y_true, yb)\n",
    "        else:\n",
    "            s = average_precision_score(y_true, p_hat, sample_weight=w)\n",
    "        if s > best_score:\n",
    "            best_score, best_t = s, t\n",
    "    return best_score, best_t\n",
    "\n",
    "def subgroup_report(y_true, p_hat, y_pred, w, group: pd.Series, name: str):\n",
    "    if group is None or group.empty:\n",
    "        return\n",
    "    rows = []\n",
    "    gser = group.astype(str)\n",
    "    for g in sorted(gser.dropna().unique()):\n",
    "        idx = gser.index[gser == g]\n",
    "        yi, pi, wi, yi_hat = y_true[idx], p_hat[idx], w[idx], y_pred[idx]\n",
    "        try:\n",
    "            auc = roc_auc_score(yi, pi, sample_weight=wi)\n",
    "        except Exception:\n",
    "            auc = np.nan\n",
    "        rows.append({\n",
    "            name: g,\n",
    "            \"n\": int(len(idx)),\n",
    "            \"prevalence_w\": float((yi*wi).sum()/wi.sum() if wi.sum() > 0 else np.nan),\n",
    "            \"AUC_w\": float(auc) if auc==auc else np.nan,\n",
    "            \"F1_w\": float(f1_score(yi, yi_hat, sample_weight=wi)) if len(np.unique(yi_hat))>1 else np.nan,\n",
    "            \"BalAcc\": float(balanced_accuracy_score(yi, yi_hat)) if len(np.unique(yi_hat))>1 else np.nan\n",
    "        })\n",
    "    df = pd.DataFrame(rows).sort_values(\"n\", ascending=False)\n",
    "    os.makedirs(\"artifacts\", exist_ok=True)\n",
    "    df.to_csv(f\"artifacts/subgroup_{name}.csv\", index=False)\n",
    "    print(f\"Saved artifacts/subgroup_{name}.csv\")\n",
    "\n",
    "def save_pipeline_safely(pipeline_or_model, path: str):\n",
    "    \"\"\"Try to joblib.dump(); if it fails, persist prep and estimator separately.\"\"\"\n",
    "    try:\n",
    "        joblib.dump(pipeline_or_model, path)\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"[warn] Could not pickle full object ({e}). Saving components.\")\n",
    "        if isinstance(pipeline_or_model, Pipeline):\n",
    "            prep = pipeline_or_model.named_steps.get(\"prep\", None)\n",
    "            est_name, est = pipeline_or_model.steps[-1]\n",
    "            if prep is not None:\n",
    "                joblib.dump(prep, path.replace(\".joblib\", \"_prep.joblib\"))\n",
    "            joblib.dump(est,  path.replace(\".joblib\", f\"_{est_name}.joblib\"))\n",
    "        else:\n",
    "            base = getattr(pipeline_or_model, \"base_estimator\", None)\n",
    "            if base is not None:\n",
    "                save_pipeline_safely(base, path.replace(\".joblib\", \"_base.joblib\"))\n",
    "\n",
    "def ensure_columns(df: pd.DataFrame, cols: List[str]) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    for c in cols:\n",
    "        if c not in out.columns:\n",
    "            out[c] = np.nan\n",
    "    return out[cols]\n",
    "\n",
    "# =========================\n",
    "# Build preprocess (pickle-safe)\n",
    "# =========================\n",
    "def build_preprocess(df_union: pd.DataFrame) -> Tuple[ColumnTransformer, List[str]]:\n",
    "    bin_cols_all = subset_existing(df_union, BINARY_12)\n",
    "    ord_cols_all = subset_existing(df_union, ORDINAL_NUMERIC)\n",
    "    cat_cols_all = subset_existing(df_union, CATEGORICAL)\n",
    "\n",
    "    binary_pipe = Pipeline([\n",
    "        (\"select\", FunctionTransformer(select_reindex_func, kw_args={\"cols\": bin_cols_all}, validate=False)),\n",
    "        (\"map12\",  FunctionTransformer(map_12_binary_func, kw_args={\"cols\": bin_cols_all}, validate=False)),\n",
    "        (\"imp\",    SimpleImputer(strategy=\"most_frequent\")),\n",
    "    ])\n",
    "\n",
    "    ordinal_pipe = Pipeline([\n",
    "        (\"select\", FunctionTransformer(select_reindex_func, kw_args={\"cols\": ord_cols_all}, validate=False)),\n",
    "        (\"clean\",  FunctionTransformer(clean_ordinals_func, kw_args={\"cols\": ord_cols_all}, validate=False)),\n",
    "        (\"imp\",    SimpleImputer(strategy=\"median\")),\n",
    "        (\"scale\",  StandardScaler()),\n",
    "    ])\n",
    "\n",
    "    categorical_pipe = Pipeline([\n",
    "        (\"select\", FunctionTransformer(select_reindex_func, kw_args={\"cols\": cat_cols_all}, validate=False)),\n",
    "        (\"imp\",    SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"ohe\",    make_ohe()),\n",
    "    ])\n",
    "\n",
    "    transformers = []\n",
    "    if len(bin_cols_all): transformers.append((\"bin\", binary_pipe, bin_cols_all))\n",
    "    if len(ord_cols_all): transformers.append((\"ord\", ordinal_pipe, ord_cols_all))\n",
    "    if len(cat_cols_all): transformers.append((\"cat\", categorical_pipe, cat_cols_all))\n",
    "\n",
    "    preprocess = ColumnTransformer(\n",
    "        transformers=transformers,\n",
    "        remainder=\"drop\",\n",
    "        sparse_threshold=0.3\n",
    "    )\n",
    "    return preprocess, (bin_cols_all + ord_cols_all + cat_cols_all)\n",
    "\n",
    "# =========================\n",
    "# Data\n",
    "# =========================\n",
    "def load_data() -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    train = pd.read_parquet(DATA_TRAIN)\n",
    "    test  = pd.read_parquet(DATA_TEST)\n",
    "    cols_needed = list(set(FEATURES + [WEIGHT_COL, TARGET_RAW]))\n",
    "    train = train[[c for c in cols_needed if c in train.columns]].copy()\n",
    "    test  = test[[c for c in cols_needed if c in test.columns]].copy()\n",
    "    return train, test\n",
    "\n",
    "# =========================\n",
    "# Models\n",
    "# =========================\n",
    "def build_models(preprocess: ColumnTransformer) -> Dict[str, object]:\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=500, max_depth=None, min_samples_leaf=10,\n",
    "        random_state=RNG, n_jobs=-1, class_weight=RF_CLASS_WEIGHT\n",
    "    )\n",
    "    l1 = LogisticRegression(\n",
    "        penalty=\"l1\", solver=\"saga\", C=0.5, max_iter=2000,\n",
    "        n_jobs=-1, random_state=RNG, class_weight=LOGIT_CLASS_WEIGHT\n",
    "    )\n",
    "\n",
    "    models = {\n",
    "        \"RF\": Pipeline([(\"prep\", preprocess), (\"rf\", rf)]),\n",
    "        \"L1\": Pipeline([(\"prep\", preprocess), (\"lasso\", l1)]),\n",
    "    }\n",
    "    models[\"RF-Cal\"] = CalibratedClassifierCV(models[\"RF\"], method=CALIBRATION_METHOD, cv=CALIBRATION_CV)\n",
    "    models[\"L1-Cal\"] = CalibratedClassifierCV(models[\"L1\"], method=CALIBRATION_METHOD, cv=CALIBRATION_CV)\n",
    "    return models\n",
    "\n",
    "# =========================\n",
    "# Evaluation\n",
    "# =========================\n",
    "def evaluate_on_test(model, Xtr, ytr, wtr, Xte, yte, wte, label: str, threshold: float = 0.5):\n",
    "    if isinstance(model, Pipeline):\n",
    "        fit_with_weights(model, Xtr, ytr, wtr)\n",
    "    else:\n",
    "        fit_calibrated(model, Xtr, ytr, wtr)\n",
    "\n",
    "    p = model.predict_proba(Xte)[:, 1]\n",
    "    ypred = (p >= threshold).astype(int)\n",
    "    metrics = {\n",
    "        \"weighted_auc\": roc_auc_score(yte, p, sample_weight=wte),\n",
    "        \"weighted_accuracy\": accuracy_score(yte, ypred, sample_weight=wte),\n",
    "        \"balanced_accuracy\": balanced_accuracy_score(yte, ypred),\n",
    "        \"weighted_f1\": f1_score(yte, ypred, sample_weight=wte),\n",
    "        \"avg_precision\": average_precision_score(yte, p, sample_weight=wte),\n",
    "        \"threshold\": threshold\n",
    "    }\n",
    "    print(f\"\\n=== {label} (thr={threshold:.2f}) ===\")\n",
    "    for k, v in metrics.items():\n",
    "        if k != \"threshold\":\n",
    "            print(f\"{k}: {v:.4f}\")\n",
    "    print(\"Confusion matrix (unweighted counts):\\n\", confusion_matrix(yte, ypred))\n",
    "    return metrics, p, ypred\n",
    "\n",
    "# =========================\n",
    "# Interpretation (lite)\n",
    "# =========================\n",
    "def interpret_models(fitted_rf: Pipeline, fitted_l1: Pipeline):\n",
    "    # RF importances\n",
    "    rf = fitted_rf.named_steps[\"rf\"]\n",
    "    prep_rf = fitted_rf.named_steps[\"prep\"]\n",
    "    n_rf = rf.feature_importances_.shape[0]\n",
    "    rf_names = feature_names_from_preprocessor(prep_rf, n_features=n_rf)\n",
    "    rf_imp = pd.Series(rf.feature_importances_, index=rf_names).sort_values(ascending=False)\n",
    "    print(\"\\nTop 20 RF importances:\")\n",
    "    print(rf_imp.head(20))\n",
    "    os.makedirs(\"artifacts\", exist_ok=True)\n",
    "    rf_imp.to_csv(\"artifacts/rf_importances.csv\")\n",
    "\n",
    "    # L1 coefficients\n",
    "    l1 = fitted_l1.named_steps[\"lasso\"]\n",
    "    prep_l1 = fitted_l1.named_steps[\"prep\"]\n",
    "    if hasattr(l1, \"coef_\"):\n",
    "        coef = l1.coef_.ravel()\n",
    "        n_l1 = coef.shape[0]\n",
    "        l1_names = feature_names_from_preprocessor(prep_l1, n_features=n_l1)\n",
    "        l1_coefs = pd.Series(coef, index=l1_names).sort_values(key=np.abs, ascending=False)\n",
    "        print(\"\\nTop 20 |L1| coefficients:\")\n",
    "        print(l1_coefs.head(20))\n",
    "        l1_coefs.to_csv(\"artifacts/l1_coefficients.csv\")\n",
    "\n",
    "# =========================\n",
    "# MAIN\n",
    "# =========================\n",
    "def main():\n",
    "    os.makedirs(\"artifacts\", exist_ok=True)\n",
    "\n",
    "    # Load\n",
    "    train, test = load_data()\n",
    "\n",
    "    # Targets & weights\n",
    "    y_train = make_binary_srh(train).to_numpy()\n",
    "    y_test  = make_binary_srh(test).to_numpy()\n",
    "    w_train = normalize_weights(train[WEIGHT_COL]) if WEIGHT_COL in train.columns else np.ones(len(train))\n",
    "    w_test  = normalize_weights(test[WEIGHT_COL])  if WEIGHT_COL  in test.columns  else np.ones(len(test))\n",
    "\n",
    "    # Features schema (exclude target)\n",
    "    all_model_cols = sorted(set(FEATURES) | set(BINARY_12) | set(ORDINAL_NUMERIC) | set(CATEGORICAL))\n",
    "    if TARGET_RAW in all_model_cols:\n",
    "        all_model_cols.remove(TARGET_RAW)\n",
    "\n",
    "    X_train_raw = train[[c for c in FEATURES if c in train.columns]].copy()\n",
    "    X_test_raw  = test[[c for c in FEATURES if c in test.columns]].copy()\n",
    "    X_train = ensure_columns(X_train_raw, all_model_cols)\n",
    "    X_test  = ensure_columns(X_test_raw,  all_model_cols)\n",
    "\n",
    "    # Preprocess (fit on union schema)\n",
    "    preprocess, used_cols = build_preprocess(pd.concat([X_train, X_test], axis=0, ignore_index=True))\n",
    "    with open(\"artifacts/feature_groups.txt\", \"w\") as f:\n",
    "        f.write(\"USED_COLS:\\n\")\n",
    "        for c in used_cols: f.write(f\"{c}\\n\")\n",
    "\n",
    "    # Prevalence snapshot\n",
    "    pd.DataFrame(\n",
    "        [class_prevalence(y_train, w_train), class_prevalence(y_test, w_test)],\n",
    "        index=[\"train\", \"test\"]\n",
    "    ).to_csv(\"artifacts/class_prevalence.csv\")\n",
    "\n",
    "    # Build models (uncalibrated + calibrated)\n",
    "    models = build_models(preprocess)\n",
    "\n",
    "    # OOF threshold tuning on Adults23 (weighted F1)\n",
    "    print(\"\\n[Threshold tuning] OOF predictions on Adults23...\")\n",
    "    thresholds = {}\n",
    "    for name in [\"RF\", \"L1\", \"RF-Cal\", \"L1-Cal\"]:\n",
    "        print(f\" - {name} OOF ...\")\n",
    "        oof = oof_predict_proba(models[name], X_train, y_train, w_train, n_splits=N_SPLITS_OOF)\n",
    "        score, thr = find_best_threshold(y_train, oof, w_train, metric=\"f1\")\n",
    "        thresholds[name] = thr\n",
    "        print(f\"   best weighted F1={score:.4f} at thr={thr:.2f}\")\n",
    "\n",
    "    # Evaluate on Adults24\n",
    "    print(\"\\n[Step] Evaluation on Adults24 (external test)\")\n",
    "    metrics_rows, preds_dict = [], {}\n",
    "    for name in [\"RF\", \"L1\", \"RF-Cal\", \"L1-Cal\"]:\n",
    "        thr = thresholds[name]\n",
    "        m, p, yhat = evaluate_on_test(\n",
    "            models[name], X_train, y_train, w_train, X_test, y_test, w_test,\n",
    "            label=name, threshold=thr\n",
    "        )\n",
    "        metrics_rows.append({\"model\": name, **m})\n",
    "        preds_dict[f\"{name}_prob\"] = p\n",
    "        preds_dict[f\"{name}_pred\"] = yhat\n",
    "\n",
    "    # Fit final uncalibrated models once for interpretation\n",
    "    from copy import deepcopy\n",
    "    rf_final = deepcopy(models[\"RF\"])\n",
    "    l1_final = deepcopy(models[\"L1\"])\n",
    "    fit_with_weights(rf_final, X_train, y_train, w_train)\n",
    "    fit_with_weights(l1_final, X_train, y_train, w_train)\n",
    "    interpret_models(rf_final, l1_final)\n",
    "\n",
    "    # Subgroup diagnostics (optional, if present)\n",
    "    if \"REGION\" in test.columns:\n",
    "        subgroup_report(y_test, preds_dict[\"RF_prob\"], preds_dict[\"RF_pred\"], w_test, test[\"REGION\"], \"REGION\")\n",
    "    if \"URBRRL23\" in test.columns:\n",
    "        subgroup_report(y_test, preds_dict[\"RF_prob\"], preds_dict[\"RF_pred\"], w_test, test[\"URBRRL23\"], \"URBRRL23\")\n",
    "\n",
    "    # Save artifacts\n",
    "    out_df = pd.DataFrame({\"srh_bin\": y_test, \"wt\": w_test})\n",
    "    for k, v in preds_dict.items():\n",
    "        out_df[k] = v\n",
    "    out_df.to_csv(\"artifacts/test_predictions.csv\", index=False)\n",
    "    pd.DataFrame(metrics_rows).to_csv(\"artifacts/test_metrics.csv\", index=False)\n",
    "\n",
    "    # Save pipelines (pickle-safe)\n",
    "    ts = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    save_pipeline_safely(models[\"RF\"],     f\"artifacts/rf_pipeline_{ts}.joblib\")\n",
    "    save_pipeline_safely(models[\"L1\"],     f\"artifacts/l1_pipeline_{ts}.joblib\")\n",
    "    save_pipeline_safely(models[\"RF-Cal\"], f\"artifacts/rf_calibrated_{ts}.joblib\")\n",
    "    save_pipeline_safely(models[\"L1-Cal\"], f\"artifacts/l1_calibrated_{ts}.joblib\")\n",
    "\n",
    "    print(\"\\nArtifacts saved to ./artifacts:\")\n",
    "    print(\" - feature_groups.txt\")\n",
    "    print(\" - class_prevalence.csv\")\n",
    "    print(\" - rf_importances.csv, l1_coefficients.csv\")\n",
    "    print(\" - test_predictions.csv\")\n",
    "    print(\" - test_metrics.csv\")\n",
    "    print(\" - rf_pipeline_*.joblib, l1_pipeline_*.joblib\")\n",
    "    print(\" - rf_calibrated_*.joblib, l1_calibrated_*.joblib\")\n",
    "    print(\" - subgroup_REGION.csv / subgroup_URBRRL23.csv (when present)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Threshold tuning] OOF predictions on Adults23...\n",
      " - RF OOF ...\n",
      "   best weighted F1=0.5634 at thr=0.55\n",
      " - L1 OOF ...\n",
      "   best weighted F1=0.5679 at thr=0.65\n",
      " - RF-Cal OOF ...\n",
      "   best weighted F1=0.5657 at thr=0.25\n",
      " - L1-Cal OOF ...\n",
      "   best weighted F1=0.5691 at thr=0.30\n",
      "\n",
      "[Step] Evaluation on Adults24 (external test)\n",
      "\n",
      "=== RF (thr=0.55) ===\n",
      "weighted_auc: 0.8574\n",
      "weighted_accuracy: 0.8512\n",
      "balanced_accuracy: 0.7664\n",
      "weighted_f1: 0.5507\n",
      "avg_precision: 0.5581\n",
      "Confusion matrix (unweighted counts):\n",
      " [[23535  3739]\n",
      " [ 1768  3587]]\n",
      "\n",
      "=== L1 (thr=0.65) ===\n",
      "weighted_auc: 0.8562\n",
      "weighted_accuracy: 0.8515\n",
      "balanced_accuracy: 0.7658\n",
      "weighted_f1: 0.5537\n",
      "avg_precision: 0.5626\n",
      "Confusion matrix (unweighted counts):\n",
      " [[23602  3672]\n",
      " [ 1787  3568]]\n",
      "\n",
      "=== RF-Cal (thr=0.25) ===\n",
      "weighted_auc: 0.8582\n",
      "weighted_accuracy: 0.8415\n",
      "balanced_accuracy: 0.7719\n",
      "weighted_f1: 0.5475\n",
      "avg_precision: 0.5579\n",
      "Confusion matrix (unweighted counts):\n",
      " [[23066  4208]\n",
      " [ 1617  3738]]\n",
      "\n",
      "=== L1-Cal (thr=0.30) ===\n",
      "weighted_auc: 0.8561\n",
      "weighted_accuracy: 0.8633\n",
      "balanced_accuracy: 0.7566\n",
      "weighted_f1: 0.5555\n",
      "avg_precision: 0.5624\n",
      "Confusion matrix (unweighted counts):\n",
      " [[24337  2937]\n",
      " [ 2030  3325]]\n",
      "\n",
      "Top 20 RF importances:\n",
      "f4     0.123159\n",
      "f43    0.086716\n",
      "f16    0.072587\n",
      "f24    0.063966\n",
      "f5     0.063441\n",
      "f17    0.050952\n",
      "f42    0.044535\n",
      "f48    0.044242\n",
      "f3     0.044228\n",
      "f49    0.028497\n",
      "f6     0.024018\n",
      "f27    0.023390\n",
      "f44    0.021657\n",
      "f25    0.020197\n",
      "f8     0.017812\n",
      "f51    0.016577\n",
      "f47    0.015742\n",
      "f45    0.014410\n",
      "f50    0.013643\n",
      "f18    0.013109\n",
      "dtype: float64\n",
      "\n",
      "Top 20 |L1| coefficients:\n",
      "f4     1.558525\n",
      "f17    0.939743\n",
      "f5    -0.935347\n",
      "f32    0.858711\n",
      "f25    0.777292\n",
      "f20    0.695627\n",
      "f16    0.692835\n",
      "f18    0.564088\n",
      "f21    0.491079\n",
      "f33    0.479121\n",
      "f34    0.449640\n",
      "f26    0.438637\n",
      "f24    0.421146\n",
      "f29    0.401425\n",
      "f8    -0.387623\n",
      "f6    -0.385581\n",
      "f12    0.326304\n",
      "f68   -0.299992\n",
      "f38    0.297483\n",
      "f23    0.296913\n",
      "dtype: float64\n",
      "Saved artifacts/subgroup_REGION.csv\n",
      "Saved artifacts/subgroup_URBRRL23.csv\n",
      "\n",
      "Artifacts saved to ./artifacts:\n",
      " - feature_groups.txt\n",
      " - class_prevalence.csv\n",
      " - rf_importances.csv, l1_coefficients.csv\n",
      " - test_predictions.csv\n",
      " - test_metrics.csv\n",
      " - rf_pipeline_*.joblib, l1_pipeline_*.joblib\n",
      " - rf_calibrated_*.joblib, l1_calibrated_*.joblib\n",
      " - subgroup_REGION.csv / subgroup_URBRRL23.csv (when present)\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
